<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ofithcheallaigh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ofithcheallaigh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-16T23:36:12+00:00</updated><id>https://ofithcheallaigh.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Literature Review Prep</title><link href="https://ofithcheallaigh.github.io/blog/2025/lit-review-data-analysis/" rel="alternate" type="text/html" title="Literature Review Prep"/><published>2025-05-29T10:30:01+00:00</published><updated>2025-05-29T10:30:01+00:00</updated><id>https://ofithcheallaigh.github.io/blog/2025/lit-review-data-analysis</id><content type="html" xml:base="https://ofithcheallaigh.github.io/blog/2025/lit-review-data-analysis/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>Any research project will typically need a literature review (LR). The point of the LR is to provide an overview and analysis of the work done to date in that research area. Sometimes the LR can be extensive.</p> <p>Since I have to carry out an extensive review, I through the best thing to do would be to get some data and do a bit of work so I could understand what journals are publishing the most articles in my research area, who are the main people working in my area, and so on.</p> <p>The data was quite easy to get from Scopus<sup><a href="#myfootnote1">1</a></sup>, once I figured out my search term (which was: <code class="language-plaintext highlighter-rouge">(TITLE-ABS-KEY("federated learning") AND (LIMIT-TO(PUBYEAR,2024)) AND (LIMIT-TO(DOCTYPE,"ar"))</code> for those interested). This search is for articles only. I am interested specifically in journal articles, mainly because it is best to limit your literature review to journals, since they are the highest standard of puiblication. This search returned 5743 articles, 5735 of which come from journals (7 are from trade journals, and 1 is from a book series). This analysis will only be considering the journal articles – also, I have just downloaded the top 1000 returned results, and ranked by citation. I ranked by citation initially because I am looking for the most popular articles, and their sources.</p> <p>Note: I found out after my initial work, I could filter futher for journal articles only with this search: <code class="language-plaintext highlighter-rouge">TITLE-ABS-KEY ("federated learning") AND (LIMIT-TO (DOCTYPE, "ar")) AND (LIMIT-TO(SRCTYPE, "j"))</code></p> <h2 id="the-development-of-federated-learning">The Development of Federated Learning</h2> <p>One thing that stands out from just looking at the information Scopus returns in the growing interst in federated learning. This can be seen in the following graph, from Scopus:</p> <p><img src="/assets/img/Blog/scopus_fl_journals_by_year.png" alt="Journals by Year"/></p> <div class="caption text-center"> <i>Federated Learning Journal Articles Published by Year (Scopus)</i> </div> <p><br/> For 2024, Scopus listed 5735 joural articles in their database, as of May, 2025, they already have 6020 articles listed. So there is growing interest in federated learning (FL).</p> <p><br/></p> <h1 id="a-look-at-the-data">A Look At the Data</h1> <h2 id="what-journals">What Journals?</h2> <p>Scopus allows you to populate a page with 200 search results, so to get my data, I selected this, and exported the data to a <code class="language-plaintext highlighter-rouge">.csv</code> file. I did this for the first five pages, to get my 1000 results. Using <code class="language-plaintext highlighter-rouge">pandas</code> in python, I read in the <code class="language-plaintext highlighter-rouge">.csv</code> files with the <code class="language-plaintext highlighter-rouge">read_csv</code> function, and concatanted them into a single DataFrame.</p> <p>Scopus also allowed me to export what I callthe meta data for my search results, in the form of a <code class="language-plaintext highlighter-rouge">.csv</code> file also, but I had a lot of issues reading that in with <code class="language-plaintext highlighter-rouge">pandas</code> – there was some encoding issue it wasn’t happy with, and the quickest way I could solve that was to save that data as an <code class="language-plaintext highlighter-rouge">.xlsx</code> files, and read it is using the <code class="language-plaintext highlighter-rouge">read_excel</code> function.</p> <p><img src="/assets/img/Blog/scopus_fl_journals_dataset_head.png" alt="Quick look at the data"/></p> <div class="caption text-center"> <i>Federated Learning Journal Dataset</i> </div> <p><br/></p> <p>The reason for this work is to try and find out what journals are publishing the popular papers, what journals are publishing the most papers, who are the big names in the field.</p> <p>So, the first thing I looked at was the paper from 2024 with the most citations. And this was:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Title: Heterogeneous Federated Learning: State-of-the-art and Research Challenges
Authors: Ye, Mang; Fang, Xiuwen; Du, Bo; Yuen, Pong C.; Tao, Dacheng
</code></pre></div></div> <p>This paper was published in ACM Computing Surveys, and has 213 citations. This journal is quite interesting – as the name suggests, they only publish surveys and the like. Their website says:</p> <blockquote> <p>Computing Surveys publishes comprehensive, readable tutorials and survey papers that give guided tours through the literature and explain topics to those who seek to learn the basics of areas outside their specialties.<sup><a href="#myfootnote2">2</a></sup></p> </blockquote> <p>And:</p> <blockquote> <p>Computing Surveys does not publish “new” research.<sup><a href="#myfootnote2">2</a></sup></p> </blockquote> <p>And surverys are great! They help you get an initial understanding, and most people starting off on a topic will use serveys. ACM state this! But surveys are not what I will want for my reviews. I will want original, new research. (Of course, surveys are helpful in guiding you tothat too!)</p> <p>From here, I wanted to see what journals are publishing new research. These then to be the transactions in specific areas. I decided to look at the amount of papers that each journal has published, thinking this seemed like a good metric – people want their work publiched in the best places, and will target them.</p> <p>So:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Count the occurrences of each "Source title"
</span><span class="n">source_title_counts_1000</span> <span class="o">=</span> <span class="n">paper_data_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Source title</span><span class="sh">"</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>

<span class="c1"># Display the counts
</span><span class="n">source_title_counts_1000</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <p>The Top 10 are:</p> <table> <thead> <tr> <th>Journal Title</th> <th>Paper Count</th> <th>Impact Factor</th> </tr> </thead> <tbody> <tr> <td>IEEE Internet of Things Journal</td> <td>98</td> <td>8.2</td> </tr> <tr> <td>IEEE Transactions on Mobile Computing</td> <td>55</td> <td>7.7</td> </tr> <tr> <td>IEEE Transactions on Consumer Electronics</td> <td>51</td> <td>4.3</td> </tr> <tr> <td>IEEE Access</td> <td>33</td> <td>3.4</td> </tr> <tr> <td>IEEE Transactions on Wireless Communications</td> <td>30</td> <td>8.9</td> </tr> <tr> <td>IEEE Transactions on Neural Networks and Learning Systems</td> <td>25</td> <td>10.2</td> </tr> <tr> <td>Future Generation Computer Systems</td> <td>23</td> <td>6.2</td> </tr> <tr> <td>Expert Systems with Applications</td> <td>21</td> <td>7.5</td> </tr> <tr> <td>IEEE Transactions on Information Forensics and Security</td> <td>20</td> <td>6.3</td> </tr> <tr> <td>ACM Computing Surveys</td> <td>18</td> <td>23.8</td> </tr> </tbody> </table> <p>The top journal is <code class="language-plaintext highlighter-rouge">IEEE Internet of Things Journal</code>. Journals will public metrics to try and help researchers (and others) get a feel for how important the journal is, but it really isn’t the only consideration when assessing how good a journal is. Other things, such as topic area and so on will come into play. But I think it is fair to say anything published by the IEEE or Elsevier, as all but the ACM Computing Surveys is, will be top quality papers. I know less about ACM, but given the impact factor, and the citations (which, I know, are linked), I am confident saying it is top quality too.</p> <h2 id="digging-deeper">Digging Deeper</h2> <p>So, not I am starting to get a feel for the types of journals I should be looking in. But, what else can the data tell us?</p> <p>We can take a look at the subject areas where the federated learning articles are being published. The meta data is useful for the work going forward:</p> <p><img src="/assets/img/Blog/scopus_fl_subject_areas.png" alt="Quick look at the data"/></p> <div class="caption text-center"> <i>Number of FL Journal Publications by Subject Area</i> </div> <p><br/></p> <p>I don’t think it will really surprise anyone that Computer Science and Engineering are the top two. Mathematics surprised me a bit, but then, people working in applied mathematics are obviously doing some work on, I would assume, various algorithms and so on. Areas related to health make a lot of sense too, as they will benefit from the privacy preserving element of federated learning.</p> <p>The next plot did surprise me though, and it is journal articles published by country:</p> <p><img src="/assets/img/Blog/scopus_fl_journals_country.png" alt="Quick look at the data"/></p> <div class="caption text-center"> <i>Number of FL Journal Publications by Country</i> </div> <p><br/></p> <p>We can see that China is, by a long way, publishing more federated learning related journal articles than anyone else. To pie chart below drives this point home a but more:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog/scopus_fl_journals_country_pie-480.webp 480w,/assets/img/Blog/scopus_fl_journals_country_pie-800.webp 800w,/assets/img/Blog/scopus_fl_journals_country_pie-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Blog/scopus_fl_journals_country_pie.png" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption text-center"> <i>Pie Chart Showing the Number of FL Journal Publications by the Top 10 Country</i> </div> <p><br/></p> <p>This chart looks at the Top 10 countries only, and we can see, of that 10, China is producing almost 50% of the work! America is only close to 13%, with India approaching 8% and the UK approaching 6%.</p> <p>The code for the pie chart plot is:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Top 10 countries only
</span><span class="n">top_10_countries_df</span> <span class="o">=</span> <span class="n">scopus_meta_data_country_df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Plot a pie chart for the top 10 countries
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">pie</span><span class="p">(</span>
    <span class="n">top_10_countries_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Country Count</span><span class="sh">"</span><span class="p">],</span>  <span class="c1"># values
</span>    <span class="n">labels</span><span class="o">=</span><span class="n">top_10_countries_df</span><span class="p">[</span><span class="sh">"</span><span class="s">COUNTRY</span><span class="sh">"</span><span class="p">],</span>  <span class="c1"># labels
</span>    <span class="n">autopct</span><span class="o">=</span><span class="sh">'</span><span class="s">%1.1f%%</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># shows percentages
</span>    <span class="n">startangle</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>  <span class="c1"># rotate pie chart for better readability
</span>    <span class="n">labeldistance</span><span class="o">=</span><span class="mf">1.15</span> <span class="c1"># distance the country names is from the edge of the chart
</span><span class="p">)</span>

<span class="c1"># Add title
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Top 10 Countries by Count</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="c1"># Show the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p>From this, I was interested to see what universities were producing the most papers (code then chart):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scopus_meta_data_affiliation_df</span>
<span class="n">top_20_affiliations_df</span> <span class="o">=</span> <span class="n">scopus_meta_data_affiliation_df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># Plot a bar chart for "Subject Area" vs "Subject Area Count"
# top_30_countries_df = scopus_meta_data_country_df.head(30)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">top_20_affiliations_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AFFILIATION</span><span class="sh">"</span><span class="p">],</span> <span class="n">top_20_affiliations_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Affiliation Count</span><span class="sh">"</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">skyblue</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Add labels and title
# plt.xlabel("Affiliation", fontsize=12)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Publication Count</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Number of Journal Publications by Affiliation</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Rotate x-axis labels for better readability
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
<span class="c1"># Show the plot
</span></code></pre></div></div> <p><img src="/assets/img/Blog/scopus_fl_affiliations.png" alt="Quick look at the data"/></p> <div class="caption text-center"> <i>Pie Chart Showing the Number of FL Journal Publications by the Top 10 Country</i> </div> <p><br/></p> <p>We can see that the <code class="language-plaintext highlighter-rouge">Ministry of Education of the People's Republic of Chain</code> is producing about twice the output of the next university, the <code class="language-plaintext highlighter-rouge">University of Electronic Science and technolofy of China</code>.</p> <h2 id="keywords">Keywords</h2> <p>The last bit of work for now, is looking at the keywords associated with these 1000 articles. The Word Cloud below shows these:</p> <p><img src="/assets/img/Blog/scopus_fl_keywords.png" alt="Quick look at the data"/></p> <div class="caption text-center"> <i>FL Journal Publication Keywords</i> </div> <p><br/></p> <p>There are a few things that stuck out to me here, specifically the <code class="language-plaintext highlighter-rouge">Unmanned_Aerial_Vehicle_(UAV)</code> keyword, and others like <code class="language-plaintext highlighter-rouge">Sematics</code>, <code class="language-plaintext highlighter-rouge">Knowledge_Distillation</code> and <code class="language-plaintext highlighter-rouge">Adversarial_Machine_Learning</code>. These terms will be useful when I am searching for newly published work.</p> <h2 id="conclusions">Conclusions?</h2> <p>The point of this work was to understand what journals I should be looking at when it comes to gathering papers for my literature review, and I think I have that information. There is still some more analysis I want to do, mainly around the individual who are doing the work, their labs and so on.</p> <p>From there, I can maybe set up alerts for work coming from these places, and from certain people.</p> <p>I was very surprised at how much more work is coming out of China, relative to America. Of course, this analysis was done just looking at FL specificially, but I get the impression from this, and from the news, that China is moving ahead with real momentum.</p> <p>Hopefully, more to come. Soon!</p> <h2 id="footnotes">Footnotes</h2> <p><a name="myfootnote1">1</a>: From the Scopus webiste: Scopus is a “Comprehensive, multidisciplinary, trusted abstract and citation database”. Researchers and other interested parties can use Scopus to look for peer-reviewed published work om a wide range of topics.</p> <p><a name="myfootnote2">2</a>: Source link: <a href="https://dl.acm.org/journal/csur/editorial-charter">ACM Computing Surveys Editorial Charter</a></p>]]></content><author><name></name></author><category term="Research"/><category term="Literature-Review,"/><category term="Data-Analysis,"/><category term="PhD"/><summary type="html"><![CDATA[Some data analysis on Scopus data to prepare for a lit. review]]></summary></entry><entry><title type="html">Exploring the F1 Dataset</title><link href="https://ofithcheallaigh.github.io/blog/2025/exploring-the-f1-dataset/" rel="alternate" type="text/html" title="Exploring the F1 Dataset"/><published>2025-05-06T10:30:01+00:00</published><updated>2025-05-06T10:30:01+00:00</updated><id>https://ofithcheallaigh.github.io/blog/2025/exploring-the-f1-dataset</id><content type="html" xml:base="https://ofithcheallaigh.github.io/blog/2025/exploring-the-f1-dataset/"><![CDATA[<h1 id="fast-f1">Fast F1</h1> <p>Sometimes you get a dataset (should it be data set?) that is just huge. And that seems to be the case with the <a href="https://docs.fastf1.dev/index.html">Fast F1</a> dataset. This thing will give you lap times, car telemetry, weather data, tyre data, and not just for the race, for the practice session, and the qualification races too. It will even give you information on a team colour!</p> <p>So yes, a large amount of data. I find that when I have a dataset that is huge, I need to play around with it, dig into it to see what I can find, to see how I can use it. And that is what I have been doing over the last few days, on-and-off.</p> <p>The first thing I wanted to do was a bit of a comparison between the same race in different years. No real reason for picking this, but, it seemed like a good place to start,so I picked the race in Australia for 2025, 2024 and 2023. I picked this race because we are not that far into the 2025 season, and the Australian race this year was quite notable.</p> <p>In 2024 and 2023, the Australian race was the third race in the calendar, but it was the first race in 2025.</p> <p>Before we can start to analyse any data, we need to set that data. With the Fast F1 api, you need to get the session data, and then you need to load that data into a cache folder (which you create yourself). You can get the session data as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">australia_2025</span> <span class="o">=</span> <span class="n">fastf1</span><span class="p">.</span><span class="nf">get_session</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="sh">'</span><span class="s">Australia</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">R</span><span class="sh">'</span><span class="p">)</span>
<span class="n">australia_2024</span> <span class="o">=</span> <span class="n">fastf1</span><span class="p">.</span><span class="nf">get_session</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="sh">'</span><span class="s">Australia</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">R</span><span class="sh">'</span><span class="p">)</span>
<span class="n">australia_2023</span> <span class="o">=</span> <span class="n">fastf1</span><span class="p">.</span><span class="nf">get_session</span><span class="p">(</span><span class="mi">2023</span><span class="p">,</span> <span class="sh">'</span><span class="s">Australia</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">R</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Here, you pass in the <code class="language-plaintext highlighter-rouge">year</code> as an <code class="language-plaintext highlighter-rouge">int</code>, the <code class="language-plaintext highlighter-rouge">race</code> as a <code class="language-plaintext highlighter-rouge">str</code>, however, it can also be an <code class="language-plaintext highlighter-rouge">int</code> if you know what race it was in the sequence of races. So, <code class="language-plaintext highlighter-rouge">3</code> for the 2023 and 2024 races, and <code class="language-plaintext highlighter-rouge">1</code> for the 2024 race. The final paramater I am passing in is <code class="language-plaintext highlighter-rouge">'R'</code>, for race. If you wanted qualifying data, you could pass in <code class="language-plaintext highlighter-rouge">'Q'</code>.</p> <p>Once you are all set, you need to load the data, as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">australia_2025</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="n">australia_2024</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="n">australia_2023</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
</code></pre></div></div> <p>And then you are set.</p> <h2 id="the-fastest-lap">The fastest Lap</h2> <p>The fastest lap is quite an obvious, and interesting place to start. With the Fast F1 api you can access the fastest lap time, sure, but you can also access the lap speeds, allowing you to plot the profiles.</p> <p>To get the fastest lap, we can do the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">australia_2025_fLap</span> <span class="o">=</span> <span class="n">australia_2025</span><span class="p">.</span><span class="n">laps</span><span class="p">.</span><span class="nf">pick_fastest</span><span class="p">()</span>
<span class="n">australia_2025_fLap_dvr</span> <span class="o">=</span> <span class="n">australia_2025_fLap</span><span class="p">[</span><span class="sh">"</span><span class="s">Driver</span><span class="sh">"</span><span class="p">]</span>
<span class="n">australia_2025_fLap_time</span> <span class="o">=</span> <span class="n">australia_2025_fLap</span><span class="p">[</span><span class="sh">"</span><span class="s">LapTime</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div> <p>And basically repeat this for each year we are interested in. With a bit more work to get the speed data from the car, we can get the fastest laps for the last three races in Australia:</p> <p><img src="/assets/img/Blog/aust_fastest_lap.png" alt="Fastest Lap Plot"/></p> <p>From the graph:</p> <ul> <li>NOR: Lando Norris, McLaren driver</li> <li>LER: Charles Leclerc, Ferrari driver</li> <li>PER: Sergio Pérez, Red Bull driver</li> </ul> <p>You will have to excuse the fact that the timings still have “0 days”, I will figure out how to remove that later on.</p> <p>There are a few interesting things about this plot:</p> <ol> <li>I would have expected Max Verstappen to have had the fastest lap either in 2023 or 2024, given he was world champion in 2023 and 2024. But then, you will wear your tyres down pushing so hard, and maybe e did not need to do that.</li> <li>Why is there a 2-3 second difference between the 2023 and 2024 races when compared to the 2025 race, and is this a significant amount of time?</li> <li>Can we understand why Leclerc, in 2024, was hitting such high speeds in the mid-section? Was this typical of all drivers in that race?</li> </ol> <p>Some of these questions will be examined here, some will be looked at later.</p> <h2 id="what-happened-in-2025">What happened in 2025?</h2> <p>So why did Norris have the fastest lap in 2025, yet was about 2 seconds slower than the 2023 and 2024 races. One thing that can have a big impact on lap times is the track conditions – if there is something that can impact a drivers ability to put the car where they want in the track, they will have to be a bit more careful. One thing the Fast F1 api lets us look at is the weather conditions, so we can see if it was raining in all three years of the race we are looking at. Once you have the session data loaded. you can get the weather data quite easily:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weather_data_2025</span> <span class="o">=</span> <span class="n">australia_2025</span><span class="p">.</span><span class="n">weather_data</span>
<span class="n">australia_rain_2025</span> <span class="o">=</span> <span class="n">weather_data_2025</span><span class="p">[</span><span class="n">weather_data_2025</span><span class="p">[</span><span class="sh">"</span><span class="s">Rainfall</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span>

<span class="n">weather_data_2024</span> <span class="o">=</span> <span class="n">australia_2024</span><span class="p">.</span><span class="n">weather_data</span>
<span class="n">australia_rain_2024</span> <span class="o">=</span> <span class="n">weather_data_2024</span><span class="p">[</span><span class="n">weather_data_2024</span><span class="p">[</span><span class="sh">"</span><span class="s">Rainfall</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span>

<span class="n">weather_data_2023</span> <span class="o">=</span> <span class="n">australia_2023</span><span class="p">.</span><span class="n">weather_data</span>
<span class="n">australia_rain_2023</span> <span class="o">=</span> <span class="n">weather_data_2023</span><span class="p">[</span><span class="n">weather_data_2023</span><span class="p">[</span><span class="sh">"</span><span class="s">Rainfall</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span>
</code></pre></div></div> <p><img src="/assets/img/Blog/rainfall_weather_data_2023_2024_2025.png" alt="Rainfall"/></p> <p>The Australian GP is 58 laps, so we can see from this plot that in 2025, there was rain for each lap of the race. It is important to note, that this will not mean every part of the track experienced rain for every minute of the race, more that there was rain on some part of the track across the race. Meanwhile, for 2023 and 2024, there was no rain during the race.</p> <p>Okay, so rain will have played a factor in a slower race, but with a time delta of about 2 seconds? That doesn’t seem like an awful lot. And to people who experience normal, everyday traffic, it isn’t. But, is it a lot in terms of F1?</p> <p>To answer this, I think looking at qualifying will give us some insights. The purpose of qualifying is to go the fastest over a single lap, with the objective of being on pole position. Or, getting as good a place on the grid as you can.</p> <p>So, a single lap, as fast as you can. Similar to the fastest lap during the race. To get this data, we need to gather the qualifying dataset:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">australia_2025_q</span> <span class="o">=</span> <span class="n">fastf1</span><span class="p">.</span><span class="nf">get_session</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="sh">"</span><span class="s">Australia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q</span><span class="sh">'</span><span class="p">)</span>
<span class="n">australia_2024_q</span> <span class="o">=</span> <span class="n">fastf1</span><span class="p">.</span><span class="nf">get_session</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="sh">"</span><span class="s">Australia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q</span><span class="sh">'</span><span class="p">)</span>
<span class="n">australia_2023_q</span> <span class="o">=</span> <span class="n">fastf1</span><span class="p">.</span><span class="nf">get_session</span><span class="p">(</span><span class="mi">2023</span><span class="p">,</span> <span class="sh">"</span><span class="s">Australia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>And then load that data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">australia_2025_q</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="n">australia_2024_q</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="n">australia_2023_q</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
</code></pre></div></div> <p>Here, I am interested in the top three qualifiers for the Australian GP in each year. For 2025, I did the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Filter for the top 3 finishers
</span><span class="n">australiaQ3_2025_top_3</span> <span class="o">=</span> <span class="n">australia_2025_q</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="n">australia_2025_q</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">"</span><span class="s">Position</span><span class="sh">"</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">]</span>

<span class="c1"># Select the LastName and Q3 columns
</span><span class="n">australiaQ3_2025_top_3</span> <span class="o">=</span> <span class="n">australiaQ3_2025_top_3</span><span class="p">[[</span><span class="sh">"</span><span class="s">LastName</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Q3</span><span class="sh">"</span><span class="p">]]</span>
<span class="n">australiaQ3_2025_top_3</span>
</code></pre></div></div> <p>I got the <code class="language-plaintext highlighter-rouge">Q3</code> results as this is the qualifying phase that determines the positions of the top 10 drivers. Qualification happens on the Saturday, the day before the race, so, different weather conditions.</p> <p>After working with the data a bit, I was able to plot the results. Here is the top 3 qualifiers for 2025:</p> <p><img src="/assets/img/Blog/australia_q3_2025.png" alt="Q3_2025"/></p> <p>Here we can see that Norris (McLaren) was quickest, followed by Piastri (McLaren), then Verstappen (Red Bull). If we note the time on the y-axis, we can that there is less that 0.4 seconds between the three drivers.</p> <p>Looking at 2024:</p> <p><img src="/assets/img/Blog/australia_q3_2024.png" alt="Q3_2024"/></p> <p>A similar situation in terms of the time between the three drivers (i.e. &lt; 0.4 seconds), with Verstappen (Red Bull) being quickest, followed by Sainz (Ferrari), then Pérez (Red Bull).</p> <p>And finally, 2023:</p> <p><img src="/assets/img/Blog/australia_q3_2023.png" alt="Q3_2023"/></p> <p>Here, we see again, Verstappen (Red Bull) is the quickest, followed by Russel (Mercedes) and then Hamilton (Mercedes). Again, the time between the top three is about 0.4 seconds.</p> <p>And this makes a bit of sense for a number of reasons. One, the teams will prepare their car for the best qualification lap possible, with just the right amount of fuel, new tyres and so one. And, two, the regulations for the cars will have been quite stable during these races, with the last major regulation change coming between 2021 and 2022.</p> <p>of course, qualifying and a fastest lap in the race are not strictly the same thing, some of the reasons why I have listed above, but it does server to show how consistent the drivers can be, and how close, in terms of time, they can be. So, I think it is fair to say that fastest lap in 2025 being about 2-3 seconds slower than previous years is significant, expecially when you consider these cars can hit speeds in the region of 300kph (~185mph).</p> <h1 id="where-am-i-going-with-this">Where am I going with this?</h1> <p>My plan here is to see if I can build a machine learning model that can be used to predict the race winners. To do this, I will really need to dig into the data, and understand what I am looking at, determine which features are best used in a predictive model and so on.</p> <p>I plan to do a series of blog posts detailing this work, and then, post predictions ahead of the the next race (whenever that may be – this is a distraction project for me!).</p> <p>I will also include the project in the Projects section of this website, and link to the code in GitHub, at the appropriate juncture.</p> <p>So, yes. As Charles Leclerc would say “Let’s go!”</p>]]></content><author><name></name></author><category term="Research"/><category term="F1,"/><category term="EDA,"/><category term="F1-Project,"/><category term="Development"/><summary type="html"><![CDATA[Initial work done using the Fast F1 API to explore F1 data]]></summary></entry><entry><title type="html">Building Knowledge Graphs</title><link href="https://ofithcheallaigh.github.io/blog/2024/building-knowledge-graphs/" rel="alternate" type="text/html" title="Building Knowledge Graphs"/><published>2024-02-17T23:20:01+00:00</published><updated>2024-02-17T23:20:01+00:00</updated><id>https://ofithcheallaigh.github.io/blog/2024/building-knowledge-graphs</id><content type="html" xml:base="https://ofithcheallaigh.github.io/blog/2024/building-knowledge-graphs/"><![CDATA[<p>An obvious question to ask would be: how do we build KGs?</p> <p>KGs have what is sometimes referred to as an organising principle, which is a critical element to KGs, because since KGs are meant to enhance data, giving our data context, the graphs representing this data must be build to follow certain principles <a href="#ref1">[1]</a>.</p> <p>We can think or the organising principles in a similar way to schemas – they organise nodes and relationships according to the fundamental ideas that are essential in the given use case. These organising principles can range from the relatively simple, such as a product line, or product taxonomy, to quite complex, such as a complete business vocabulary <a href="#ref2">[2]</a>. It can be helpful to think of a KGs organising principle as a conceptual map.</p> <h1 id="references">References</h1> <p><a name="ref1">[1]</a> <a href="https://learning.oreilly.com/library/view/knowledge-graphs/9781098104863/ch02.html">Knowledge Graphs (Ch.1)</a> - Jesus Barrasa, Amy E. Holder, Jim Webber</p> <p><a name="ref2">[2]</a> <a href="https://neo4j.com/blog/what-is-knowledge-graph/">Neo4j - What is a Knowledge Graph</a></p>]]></content><author><name></name></author><category term="Research"/><category term="Knowledge-Graphs,"/><category term="AI"/><summary type="html"><![CDATA[part 2 in a series of posts on knowledge graphs]]></summary></entry><entry><title type="html">A Intro to Knowledge Graphs</title><link href="https://ofithcheallaigh.github.io/blog/2024/knowledge-graphs/" rel="alternate" type="text/html" title="A Intro to Knowledge Graphs"/><published>2024-02-16T23:39:01+00:00</published><updated>2024-02-16T23:39:01+00:00</updated><id>https://ofithcheallaigh.github.io/blog/2024/knowledge-graphs</id><content type="html" xml:base="https://ofithcheallaigh.github.io/blog/2024/knowledge-graphs/"><![CDATA[<h1 id="introduction-to-kgs">Introduction to KGs</h1> <h2 id="introduction">Introduction</h2> <p>Over the course of the last decade, graph data has become ubiquitous, underpinning everything from consumer facing systems like navigation and social networks, to critical infrastructure, such as supply chains and policing.</p> <p>Through research, and practical implementation, the concept of knowledge graphs [KG] has been developed to support the extraction of knowledge from data. This knowledge is used to provide context to the data.</p> <p>It is important to understand that there is a distinction between the ‘graph’ of knowledge graphs, and a chart, such as you would see when plotting time-series data, for example. A graph is a simple structure where we used nodes (or vertices) connected by relationships (or edges) to create high-fidelity models of a domain <a href="#ref1">[1]</a>.</p> <p>The image below is of a representation of a KG:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/simple_kg-480.webp 480w,/assets/img/simple_kg-800.webp 800w,/assets/img/simple_kg-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/simple_kg.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> KG Image [[1]](#ref1). </div> <p>These graphs can be referred to an networks – they are a powerful way to describe how things are connected.</p> <p>Some graph models, like the <em>property graph</em>, allow for both nodes and relationships to contain <em>properties</em>. A property graph consists objects or vertices, and a set of arrows or edges, connecting the objects. Vertices and edges can have multiple properties, which are represented as key-value pairs <a name="ref2">[2]</a>. An example of this kind of structure can be seen if we think about a bank, where the customer accounts can be the vertices, and the transfers between accounts can be the relationships. The data in a graph can be analysed using the connections and relationships between them. Graph analytics, such as PageRank can be used to measure the relative importance of the data, based on the relationships between them.</p> <h2 id="property-graphs">Property Graphs</h2> <p>As stated, a property graph consists of a set of objects, or vertices, and a set of arrows, or edges, connecting the objects.</p> <p>Each vertex has a unique identifier and can have:</p> <ol> <li>A set of outgoing edges.</li> <li>A set of incoming edges.</li> <li>A collection of properties.</li> </ol> <p>Each edge has a unique identifier and can have:</p> <ol> <li>An outgoing vertex.</li> <li>An incoming vertex.</li> <li>A text label that describes the relationship between the two vertices it connects.</li> <li>A number of properties.</li> </ol> <p>The figure below illustrates this relationship in a simple property graph which contains two vertices and one edge.</p> <div class="row mt-3 justify-content-center"> <div class="col-sm-8 mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/property_graph_relationship-480.webp 480w,/assets/img/property_graph_relationship-800.webp 800w,/assets/img/property_graph_relationship-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/property_graph_relationship.png" class="img-fluid rounded z-depth-1" width="90%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption text-center"> Image shows Property Graph relationships. </div> <p>In Fig <a href="#fig2">[2]</a> the vertices have identifiers <code class="language-plaintext highlighter-rouge">1</code> and <code class="language-plaintext highlighter-rouge">2</code>. Each contains two properties: <code class="language-plaintext highlighter-rouge">name</code> and <code class="language-plaintext highlighter-rouge">age</code>. The edge is outgoing from <code class="language-plaintext highlighter-rouge">1</code> and incoming to <code class="language-plaintext highlighter-rouge">2</code>, and the edge has the text label <code class="language-plaintext highlighter-rouge">knows</code> and a property <code class="language-plaintext highlighter-rouge">type</code> identifying the type of relationship between vertices <code class="language-plaintext highlighter-rouge">1</code> and <code class="language-plaintext highlighter-rouge">2</code>.</p> <p>A property graph can have self-edges, which is an edge whose source and destination vertex are the same.</p> <p>The property graph model is the most popular model for modern databases, and, as such, a popular tool for creating knowledge graphs.</p> <ul> <li><strong>Nodes</strong> can contain zero or more properties, which are key-value pairs, representing entity data, such as the price of an item or a date of birth. Nodes can have zero or more labels, which declares the nodes purpose in the graph, such as representing customers or products.</li> <li><strong>Relationships</strong> represent how entities interrelate. Relationships have a type, such as “bought” or “liked”, and have a direction, for example going from one node to another, or back to the same node. Relationships can contain zero or more properties, which are key-value pairs<sup><a href="#myfootnote1">1</a></sup> representing some characteristics of the link, such as timestamps or distance. Also, relationships never dangle – there is always a start and an end node (which can be the same node).</li> </ul> <p>Figure <a href="#fig3">[3]</a> shows a more detailed KG, which is taken directly from <a href="#ref1">[1]</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/larger_graph-480.webp 480w,/assets/img/larger_graph-800.webp 800w,/assets/img/larger_graph-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/larger_graph.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image shows Property Graph relationships. </div> <p>We can see in Fig <a href="#fig3">[3]</a> that each node has a label that represents a role in the graph. We can see that some nodes are labelled as <code class="language-plaintext highlighter-rouge">Person</code>, which represents people, and others are labelled as <code class="language-plaintext highlighter-rouge">Place</code>, which represents places.</p> <p>As each node will have properties stored inside, such as <code class="language-plaintext highlighter-rouge">name: Rose</code>, and <code class="language-plaintext highlighter-rouge">gender: f</code>, which tells us the Rosa is a female person. We can also see that <code class="language-plaintext highlighter-rouge">Karl</code> and <code class="language-plaintext highlighter-rouge">Fred</code> have nodes with slightly different properties, and this is not a problem<sup><a href="#myfootnote2">2</a></sup>.</p> <p>We can see in Fig. <a href="#fig3">[3]</a> that the relations are deeper because they have a type, a direction and can have operational properties on them. We can see from the figure that the <code class="language-plaintext highlighter-rouge">Person</code> with the property <code class="language-plaintext highlighter-rouge">name: Rosa</code> has an outgoing <code class="language-plaintext highlighter-rouge">LIVES_IN</code> relationship with the property <code class="language-plaintext highlighter-rouge">since: 2020</code> to the <code class="language-plaintext highlighter-rouge">Place</code> node with <code class="language-plaintext highlighter-rouge">city: Berlin</code> property.</p> <p>In the property graph model, there are no limits to the number of nodes or the relationships that connect them. Some nodes are connected in dense, complicated ways, while others can be sparsely connected. The manner of connection is determined by the problem domain. Nodes can also have many properties, or few properties, or even, none at all. Some relationships can have lots of properties, and many have none at all.</p> <h2 id="motivation">Motivation</h2> <p>Recently, there has been increased interest in KG, due, in part because graph technology has accelerated, and also because there is a strong demand to use, and make sense of the data companies and organisations have.</p> <p>Decision making needs to be quick, but organisations can be slow to react due to the lack of timely and accurate data. Historical data may lose its relevance as time moves forward, so organisations seek new ways to gather and learn from data. Organisations will seek ways to gather rapid insights and recommendations across their business, from customer experiences and product feedback, from patient experiences and outcomes. These insights will allow for new product innovations, heightened fraud detection, and automation. In short, <strong>we need contextualised data to generate data knowledge</strong>.</p> <h2 id="kg-definitions">KG Definitions</h2> <p>KGs are a specific type of graph, with an emphasis on contextual understanding, meaning they should not be confused with the type of graph used to display information. They are an way to describe real-world details (such as things, places, events) through a linked set of facts. This information is given in a way that is understandable by humans, and by machines. KGs use an operating principle to allow an operator (be that a person, or a computer) to reason about the data in the graph. This operating principle, or organising principle, provides an additional layer of data (metadata) that will add connected context, which can be used to support reasoning and knowledge discovery.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p><a name="myfootnote1">1</a>: A key-value pair (KVP) is a data structure that associates two related pieces of data, a key and a value. A key is a constant that defines the data set. For example, a key could be “gender” or “colour”. A value is a variable that belongs to the data set. For example, a value could be “male/female” or “green”.</p> <p><a name="myfootnote2">2</a>: If we wanted to make sure that all <code class="language-plaintext highlighter-rouge">person</code> nodes have the same property keys, we can apply <em>constraints</em> to the label, ensuring those properties exist, are unique, etc.</p> <h2 id="references">References</h2> <p><a name="ref1">[1]</a> <a href="https://learning.oreilly.com/library/view/knowledge-graphs/9781098104863/ch01.html">Knowledge Graphs (Ch.1)</a> - Jesus Barrasa, Amy E. Holder, Jim Webber</p> <p><a name="ref2">[2]</a> <a href="https://docs.oracle.com/en/database/oracle/property-graph/24.4/spgdg/introduction-property-graphs.html">Graph Developer’s Guide for Property Graphs</a></p> <p>For more information, check out my <a href="/blog/2024/building-knowledge-graphs/">next post</a>.</p>]]></content><author><name></name></author><category term="Research"/><category term="Knowledge-Graphs,"/><category term="AI"/><summary type="html"><![CDATA[A post about knowledge graphs]]></summary></entry></feed>